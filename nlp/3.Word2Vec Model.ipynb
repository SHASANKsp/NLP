{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Wikipedia (/ˌwɪkɪˈpiːdiə/ (About this soundlisten), /ˌwɪkiˈpiːdiə/ (About this soundlisten) WIK-ih-PEE-dee-ə)\n",
    "is a multilingual, web-based, free-content encyclopedia project supported by the Wikimedia Foundation and based on a model of \n",
    "openly editable content. The name \"Wikipedia\" is a portmanteau of the words wiki (a technology for creating collaborative\n",
    "websites, from the Hawaiian word wiki, meaning \"quick\") and encyclopedia. Wikipedia's articles provide links designed to \n",
    "guide the user to related pages with additional information.\n",
    "\n",
    "Wikipedia is written collaboratively by largely anonymous volunteers who write without pay. Anyone with \n",
    "Internet access can write and make changes to Wikipedia articles, except in limited cases where editing is\n",
    "restricted to prevent disruption or vandalism. Users can contribute anonymously, under a pseudonym, \n",
    "or, if they choose to, with their real identity. The fundamental principles by which Wikipedia operates are t\n",
    "he five pillars. The Wikipedia community has developed many policies and guidelines to improve the encyclopedia;\n",
    "however, it is not a formal requirement to be familiar with them before contributing.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',paragraph)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, min_count=1)\n",
    "words = model.wv.vocab\n",
    "# Finding Word Vectors\n",
    "vector = model.wv['wikipedia']\n",
    "# Most similar words\n",
    "similar = model.wv.most_similar('except')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
